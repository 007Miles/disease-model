{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 1. Connecting to the Azure ML workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1724487548195
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"59b214a7-65cd-41ae-b95a-6d56d0039476\",\n",
        "    resource_group_name=\"disease-detection-m-dep-res\",\n",
        "    workspace_name=\"disease-detection-workspace\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create a job environment for pipeline steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1724487550971
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment with name aml-deploynment-demo is registered to workspace, the environment version is 0.1.1\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-deploynment-demo\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for demo pipeline\",\n",
        "    tags={\"scikit-learn\": \"0.24.2\"},\n",
        "    conda_file=os.path.join(\"./dependencies\", \"env_config.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    version=\"0.1.1\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Creating ML Components for Our Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create component 1: data prep (using programmatic definition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1724487559295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mUploading data_preprocessing (0.0 MBs):   0%|          | 0/1861 [00:00<?, ?it/s]\r\u001b[32mUploading data_preprocessing (0.0 MBs): 100%|██████████| 1861/1861 [00:00<00:00, 40680.23it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component data_preprocessing_component with Version 2024-08-24-08-19-15-1754573 is registered\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "data_preprocessing_component = command(\n",
        "    name=\"data_preprocessing_component\",\n",
        "    display_name=\"Data preparation for training\",\n",
        "    description=\"reads a .xl input, split the input to train and test\",\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_folder\"),\n",
        "        \"test_train_ratio\": Input(type=\"number\"),\n",
        "    },\n",
        "    outputs=dict(\n",
        "        train_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "        test_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    ),\n",
        "    # The source folder of the component\n",
        "    code=\"./components/data_preprocessing\",\n",
        "    command=\"\"\"python preprocessing.py \\\n",
        "            --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} \\\n",
        "            --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}} \\\n",
        "            \"\"\",\n",
        "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
        ")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "data_preprocessing_component = ml_client.create_or_update(data_preprocessing_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_preprocessing_component.name} with Version {data_preprocessing_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create component 2: training (using yaml definition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "- The second component that we'll create will consume the training and test data.\n",
        "- In model training script after the model is trained, the model file is saved and registered to the workspace. so we can use the registered model in inferencing endpoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "we create training script and its yml file inside the components/training dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**create your component using load_component()**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1724487559479
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "training_component = load_component(source=os.path.join(\"./components/training\", \"training.yaml\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Now create and register the component:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1724487563799
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mUploading training (0.0 MBs):   0%|          | 0/4328 [00:00<?, ?it/s]\r\u001b[32mUploading training (0.0 MBs): 100%|██████████| 4328/4328 [00:00<00:00, 91794.21it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component train_credit_defaults_model with Version 2024-08-24-08-19-20-8179980 is registered\n"
          ]
        }
      ],
      "source": [
        "# Now we register the component to the workspace\n",
        "training_component = ml_client.create_or_update(training_component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {training_component.name} with Version {training_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Create the pipeline from components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Here, we'll use input data. Then call the components and connect them via their inputs /outputs identifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To code the pipeline, we use a specific `@dsl.pipeline` decorator that identifies the Azure ML pipelines. In the decorator, we can specify the pipeline description and default resources like compute (serverless is used here) and storage. Like a python function, pipelines can have inputs, you can then create multiple instances of a single pipeline with different inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1724487564126
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# The dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def disease_random_forest_pipeline(\n",
        "    pipeline_job_data_input,\n",
        "    pipeline_job_test_train_ratio,\n",
        "    pipeline_job_n_estimators,\n",
        "    pipeline_job_registered_model_name,\n",
        "):\n",
        "    # using data_prep_function like a python call with its own inputs\n",
        "    data_preprocessing_job = data_preprocessing_component(\n",
        "        data=pipeline_job_data_input,\n",
        "        test_train_ratio=pipeline_job_test_train_ratio,\n",
        "    )\n",
        "\n",
        "    # using train_func like a python call with its own inputs\n",
        "    training_job = training_component(\n",
        "        train_data=data_preprocessing_job.outputs.train_data,  # note: using outputs from previous step\n",
        "        test_data=data_preprocessing_job.outputs.test_data,  # note: using outputs from previous step\n",
        "        n_estimators=pipeline_job_n_estimators,  # note: using a pipeline input as parameter\n",
        "        registered_model_name=pipeline_job_registered_model_name,\n",
        "    )\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"pipeline_job_train_data\": data_preprocessing_job.outputs.train_data,\n",
        "        \"pipeline_job_test_data\": data_preprocessing_job.outputs.test_data,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Use our pipeline definition to instantiate a pipeline with your dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1724487564408
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "data_asset = ml_client.data.get(\"disease\", version=\"1\")\n",
        "\n",
        "registered_model_name = \"disease_random_forest_model\"\n",
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "pipeline = disease_random_forest_pipeline(\n",
        "    pipeline_job_data_input=Input(path=data_asset.id,\n",
        "                type=AssetTypes.URI_FILE,\n",
        "                mode=InputOutputModes.RO_MOUNT\n",
        "            ),\n",
        "    pipeline_job_test_train_ratio=0.15,\n",
        "    pipeline_job_n_estimators=10,\n",
        "    pipeline_job_registered_model_name=registered_model_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Submit the job "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1724487567956
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
            "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
          ]
        }
      ],
      "source": [
        "# submit the pipeline job\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"e2e_registered_components_pipeline\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
